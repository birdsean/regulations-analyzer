{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data/ecfr_contents.csv into df\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "df_contents = pl.read_csv('data/ecfr_contents.csv', ignore_errors=True)\n",
    "\n",
    "# convert contents to string\n",
    "df_contents = df_contents.with_columns(\n",
    "    df_contents['contents'].cast(pl.String)\n",
    ")\n",
    "\n",
    "df_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a space char after every \"head\" value\n",
    "df_counted = df_contents.with_columns([\n",
    "    pl.concat_str([pl.col(\"head\"), pl.lit(\" \")]).alias(\"head\")\n",
    "])\n",
    "\n",
    "# create new column with head and contents with \"join\"\n",
    "df_counted = df_counted.with_columns([\n",
    "    pl.concat_str([pl.col(\"head\"), pl.col(\"contents\")]).alias(\"head_and_contents\")\n",
    "])\n",
    "\n",
    "# remove all URLs from head_and_contents\n",
    "df_counted = df_counted.with_columns([\n",
    "    pl.col(\"head_and_contents\").str.replace_all(r\"http\\S+\", \" \").alias(\"head_and_contents\")\n",
    "])\n",
    "\n",
    "# modify all head_and_contents to be just letters and keep all possible whitespace\n",
    "df_counted = df_counted.with_columns([\n",
    "    pl.col(\"head_and_contents\").str.replace_all(r\"[^a-zA-Z]\", \" \").alias(\"head_and_contents\")\n",
    "])\n",
    "\n",
    "df_counted = df_counted.drop([\"head\", \"contents\"])\n",
    "\n",
    "# lowercase all words\n",
    "df_counted = df_counted.with_columns([\n",
    "    pl.col(\"head_and_contents\").str.to_lowercase().alias(\"head_and_contents\")\n",
    "])\n",
    "\n",
    "df_counted = df_counted.with_columns([\n",
    "    pl.col(\"head_and_contents\").str.split(\" \").list.len().alias(\"word_count\"),\n",
    "    pl.col(\"head_and_contents\").str.split(\" \").list.eval(pl.element().value_counts()).alias(\"word_count_of_each_word\"),\n",
    "])\n",
    "\n",
    "df_counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode the word_count_of_each_word column\n",
    "df_exploded_counts = df_counted.explode(\"word_count_of_each_word\")\n",
    "\n",
    "df_exploded_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where word_count_of_each_word is null\n",
    "df_tranformed_counts = df_exploded_counts.filter(pl.col(\"word_count_of_each_word\").is_not_null())\n",
    "\n",
    "# word_count_of_each_word has type struct[2], first value will be the word, second value will be the count\n",
    "# split the struct into two columns\n",
    "\n",
    "df_tranformed_counts = df_tranformed_counts.with_columns([\n",
    "    pl.col(\"word_count_of_each_word\").struct.unnest()\n",
    "])\n",
    "\n",
    "df_tranformed_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print names of cols\n",
    "print(df_tranformed_counts.columns)\n",
    "\n",
    "# rename count to word_count and '' (blank col) t0 word_value\n",
    "df_named_counts = df_tranformed_counts.with_columns([\n",
    "    pl.col(\"\").alias(\"word_value\"),\n",
    "    pl.col(\"count\").alias(\"word_count\")\n",
    "])\n",
    "\n",
    "# drop the prev cols\n",
    "df_named_counts = df_named_counts.drop([\"word_count_of_each_word\", \"\", \"count\", \"children_ids\", \"type\", \"n\"])\n",
    "\n",
    "# add new \"word_length\" column\n",
    "df_named_counts = df_named_counts.with_columns([\n",
    "    pl.col(\"word_value\").str.len_chars().alias(\"word_length\")\n",
    "])\n",
    "\n",
    "# with polars, sort by the longest \"word_value\" char count\n",
    "df_named_counts = df_named_counts.sort(\"word_length\", descending=True)\n",
    "df_named_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize by volume\n",
    "df_volume_grouped = df_named_counts.group_by(['volume', 'word_value']).agg([\n",
    "    pl.sum(\"word_count\").alias(\"word_count\")\n",
    "])\n",
    "\n",
    "df_volume_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chapter_grouped = df_named_counts.group_by(['volume', 'chapter', 'word_value']).agg([\n",
    "    pl.sum(\"word_count\").alias(\"word_count\")\n",
    "])\n",
    "\n",
    "df_chapter_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subchapter_grouped = df_named_counts.group_by(['volume', 'chapter', 'subchapter', 'word_value']).agg([\n",
    "    pl.sum(\"word_count\").alias(\"word_count\")\n",
    "])\n",
    "df_subchapter_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_grouped = df_named_counts.group_by(['volume', 'chapter', 'subchapter', 'part', 'word_value']).agg([\n",
    "    pl.sum(\"word_count\").alias(\"word_count\")\n",
    "])\n",
    "\n",
    "df_part_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subpart_grouped = df_named_counts.group_by(['volume', 'chapter', 'subchapter', 'part', 'subpart', 'word_value']).agg([\n",
    "    pl.sum(\"word_count\").alias(\"word_count\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_grouped.write_csv('data/word_count_by_volume.csv')\n",
    "df_chapter_grouped.write_csv('data/word_count_by_chapter.csv')\n",
    "df_subchapter_grouped.write_csv('data/word_count_by_subchapter.csv')\n",
    "df_part_grouped.write_csv('data/word_count_by_part.csv')\n",
    "df_subpart_grouped.write_csv('data/word_count_by_subpart.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regulations-analyzer-wDkv0VDd-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

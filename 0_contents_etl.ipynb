{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xmltodict\n",
    "import uuid\n",
    "\n",
    "BASE_URL = 'https://www.ecfr.gov'\n",
    "TITLES_PATH = '/api/versioner/v1/titles.json'\n",
    "REQUEST_DATE = '2025-02-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_dict(title):\n",
    "    url = f'{BASE_URL}/api/versioner/v1/full/{REQUEST_DATE}/title-{title}.xml'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f'Failed to fetch content for title {title}, ')\n",
    "    \n",
    "    dict_data = xmltodict.parse(response.text)\n",
    "    return dict_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def cache_content_dict(title, content_dict):\n",
    "    content_json = json.dumps(content_dict)\n",
    "    with open(f'./data/content-{title}.json', 'w') as f:\n",
    "        f.write(content_json)\n",
    "\n",
    "def read_content_dict(title):\n",
    "    try:\n",
    "        with open(f'./data/content-{title}.json', 'r') as f:\n",
    "            content_json = f.read()\n",
    "            return json.loads(content_json)\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "url = BASE_URL + TITLES_PATH\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise RuntimeError(f'Failed to get titles: {response.status_code}')\n",
    "\n",
    "parsed = response.json()\n",
    "\n",
    "content_by_title = {}\n",
    "\n",
    "for title_obj in parsed['titles']:\n",
    "    title_id = title_obj['number']\n",
    "    print(f'Fetching content for title {title_obj[\"number\"]}')\n",
    "    if title_id == 35 or title_id == 7:\n",
    "        continue  # skip title 35 b/c it doesn't exist, skip 7 b/c the API doesn't respond well to 7\n",
    "    content_dict = read_content_dict(title_id)\n",
    "\n",
    "    if content_dict is None:\n",
    "        content_dict = get_content_dict(title_id)\n",
    "        cache_content_dict(title_id, content_dict)\n",
    "\n",
    "    content_by_title[title_id] = content_dict['ECFR']\n",
    "\n",
    "print(f\"Key in content_by_title: {content_by_title.keys()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def traverse_and_extract(data, extracted):\n",
    "    if isinstance(data, dict):\n",
    "        obj_id = str(uuid.uuid4())  # Generate a unique ID\n",
    "        new_dict = {\"id\": obj_id, **{k: v for k, v in data.items() if not str(k).startswith(\"DIV\")}}  # Exclude \"DIV\" fields\n",
    "        \n",
    "        # Handle different levels of DIV fields\n",
    "        for k in list(data.keys()):\n",
    "            string_k = str(k)\n",
    "            if string_k.startswith(\"DIV\"):\n",
    "                if isinstance(data[k], list):\n",
    "                    new_dict[k] = [traverse_and_extract(item, extracted) for item in data[k]]\n",
    "                else:\n",
    "                    new_dict[k] = [traverse_and_extract(data[k], extracted)]\n",
    "        \n",
    "        extracted.append(new_dict)\n",
    "        return obj_id\n",
    "    \n",
    "    return data  # If not a dict, return as-is\n",
    "\n",
    "def transform(parsed_data):\n",
    "    extracted = []\n",
    "    root_id = traverse_and_extract(parsed_data, extracted)\n",
    "    return {\"root_id\": root_id, \"objects\": extracted}\n",
    "\n",
    "def clean_p_tags(data):\n",
    "    # if its a string, return it\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    #if its a dict, return \"#text\" value\n",
    "    if isinstance(data, dict):\n",
    "        content = ''\n",
    "        if \"#text\" in data:\n",
    "            content += data[\"#text\"]\n",
    "        if \"I\" in data and isinstance(data[\"I\"], str):\n",
    "            content += data[\"I\"]\n",
    "        return content\n",
    "    \n",
    "    # if it is a list, clean_p_tags each item\n",
    "    if isinstance(data, list):\n",
    "        return \" \".join([clean_p_tags(item) for item in data])\n",
    "\n",
    "    if not data:\n",
    "        return \"\"    \n",
    "    raise ValueError(f'Unexpected data type: {type(data)}')\n",
    "\n",
    "def join_p_tags(data):\n",
    "    if isinstance(data, dict):\n",
    "        for k in data.keys():\n",
    "            if k == \"P\":\n",
    "                cleaned_p_values = clean_p_tags(data[k])\n",
    "                if isinstance(cleaned_p_values, str):\n",
    "                    data[k] = cleaned_p_values\n",
    "                elif isinstance(cleaned_p_values, dict):\n",
    "                    data[k] = \" \".join(cleaned_p_values)\n",
    "            else:\n",
    "                join_p_tags(data[k])\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            join_p_tags(item)\n",
    "\n",
    "    return data\n",
    "\n",
    "def clean_div_names(data):\n",
    "    for obj in data:\n",
    "        keys_to_replace = []\n",
    "        for k in obj.keys():\n",
    "            if k.startswith(\"DIV\"):\n",
    "                keys_to_replace.append(k)\n",
    "        for k in keys_to_replace:\n",
    "            obj[\"DIV\"] = obj.pop(k)\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_dates(data):\n",
    "    for obj in data:\n",
    "        if \"Volume\" in obj:\n",
    "            obj[\"AMMEND_DATE\"] = obj[\"Volume\"][\"@AMDDATE\"]\n",
    "\n",
    "    return data\n",
    "\n",
    "all_objects = []\n",
    "for content in content_by_title.values():\n",
    "    objects = transform(content)\n",
    "    print(f'Count of local objects is {len(objects[\"objects\"])}')\n",
    "    p_tagged = join_p_tags(objects[\"objects\"])\n",
    "    cleaned_divs = clean_div_names(p_tagged)\n",
    "    extracted_dates = extract_dates(cleaned_divs)\n",
    "    all_objects.extend(extracted_dates)\n",
    "\n",
    "print(f'Count of all objects is {len(all_objects)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune items\n",
    "pruned = []\n",
    "whitelist_columns = [\"id\", \"@TYPE\", \"@VOLUME\", \"@N\", \"HEAD\", \"P\", \"DIV\", \"AMMEND_DATE\"]\n",
    "for obj in all_objects:\n",
    "    pruned_obj = {k: v for k, v in obj.items() if k in whitelist_columns}\n",
    "    pruned.append(pruned_obj)\n",
    "\n",
    "df_items = pd.DataFrame(pruned)\n",
    "df_items = df_items.rename(columns={\"P\": \"contents\", \"@N\": \"n\", \"@VOLUME\": \"volume\", \"@TYPE\": \"type\", \"HEAD\": \"head\", \"DIV\": \"children_ids\"})\n",
    "\n",
    "# replace NaN with empty string, except for children_ids, make that an empty list\n",
    "df_items[\"contents\"] = df_items[\"contents\"].fillna(\"\")\n",
    "df_items[\"n\"] = df_items[\"n\"].fillna(\"\")\n",
    "df_items[\"volume\"] = df_items[\"volume\"].fillna(\"\")\n",
    "df_items[\"type\"] = df_items[\"type\"].fillna(\"\")\n",
    "df_items[\"head\"] = df_items[\"head\"].fillna(\"\")\n",
    "df_items[\"children_ids\"] = df_items[\"children_ids\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# index on id\n",
    "df_items = df_items.set_index(\"id\")\n",
    "\n",
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all where type is TITLE\n",
    "df_items[df_items[\"type\"] == \"TITLE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_transformed = df_items.copy()\n",
    "\n",
    "hierarchy = [\"TITLE\", \"CHAPTER\", \"SUBCHAP\", \"PART\", \"SUBPART\", \"SECTION\"]\n",
    "\n",
    "# for each item if type TITLE, add it's \"n\" as \"title_id\" of its immediate children\n",
    "def add_title_id(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"type\"] == \"TITLE\":\n",
    "            title_id = row[\"n\"]\n",
    "            children_ids = row[\"children_ids\"]\n",
    "            for child_id in children_ids:\n",
    "                df.at[child_id, \"title\"] = title_id\n",
    "\n",
    "# for each item of type CHAPTER, add it's \"n\" as \"chapter\" of its immediate children and propogate title_id\n",
    "def add_chapter_id(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"type\"] == \"CHAPTER\":\n",
    "            chapter_id = row[\"n\"]\n",
    "            children_ids = row[\"children_ids\"]\n",
    "            for child_id in children_ids:\n",
    "                df.at[child_id, \"chapter\"] = chapter_id\n",
    "                df.at[child_id, \"title\"] = row[\"title\"]\n",
    "\n",
    "def add_subchapter_id(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"type\"] == \"SUBCHAP\":\n",
    "            subchapter_id = row[\"n\"]\n",
    "            children_ids = row[\"children_ids\"]\n",
    "            for child_id in children_ids:\n",
    "                df.at[child_id, \"subchapter\"] = subchapter_id\n",
    "                df.at[child_id, \"chapter\"] = row[\"chapter\"]\n",
    "                df.at[child_id, \"title\"] = row[\"title\"]\n",
    "\n",
    "def add_part_id(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"type\"] == \"PART\":\n",
    "            part_id = row[\"n\"]\n",
    "            children_ids = row[\"children_ids\"]\n",
    "            for child_id in children_ids:\n",
    "                df.at[child_id, \"part\"] = part_id\n",
    "                df.at[child_id, \"subchapter\"] = row.get(\"subchapter\", \"\")\n",
    "                df.at[child_id, \"chapter\"] = row[\"chapter\"]\n",
    "                df.at[child_id, \"title\"] = row[\"title\"]\n",
    "\n",
    "def add_subpart_id(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"type\"] == \"SUBPART\":\n",
    "            subpart_id = row[\"n\"]\n",
    "            children_ids = row[\"children_ids\"]\n",
    "            for child_id in children_ids:\n",
    "                df.at[child_id, \"subpart\"] = subpart_id\n",
    "                df.at[child_id, \"part\"] = row[\"part\"]\n",
    "                df.at[child_id, \"subchapter\"] = row.get(\"subchapter\", \"\")\n",
    "                df.at[child_id, \"chapter\"] = row[\"chapter\"]\n",
    "                df.at[child_id, \"title\"] = row[\"title\"]\n",
    "\n",
    "add_title_id(df_items_transformed)\n",
    "add_chapter_id(df_items_transformed)\n",
    "add_subchapter_id(df_items_transformed)\n",
    "add_part_id(df_items_transformed)\n",
    "add_subpart_id(df_items_transformed)\n",
    "\n",
    "# display all where type is SECTION\n",
    "df_content_sections = df_items_transformed[df_items_transformed[\"type\"] == \"SECTION\"]\n",
    "df_content_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content_sections.to_csv(\"data/ecfr_contents.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regulations-analyzer-wDkv0VDd-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
